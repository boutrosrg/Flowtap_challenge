# 1. Engineering a Data Set
#' dataEngineering(l, m, st) generates a vector of random numbers with given mean & standard deviation
#' @param l : length of the generated vector
#' @param m : mean of the generated vector
#' @param stdDev : standard deviation of the generated vector
#' @return data : generated vector
#' @author Boutros El-Gamil
dataEngineering<- function(l, m, stdDev){
  # set a seed number to guarantee that we obtain same result each time
  set.seed(1200)
  
  # generate random vector of numbers from normal dist. with size l, mean m, and std. div. stdDev
  data = rnorm(l, m, stdDev)
  
  # print first & second moments
  print(paste0("data mean:    ", round(mean(data), 2)))
  print(paste0("data sd:      ", round(sd(data), 2)))
  return(data)
}

# 2. Writing a Simulation
#' getAvgRatio(iter, Ran_g, Ran_b, sample_size, num_children) 
#' compute the average ratio of male children using simulation technique
#' @param iter : number of iterations to generate the sample search space
#' @param Ran_g : vector of simulated values of the prob. that a child is a girl
#' @param Ran_b : vector of simulated values of the prob. that a child is a boy
#' @param sample_size : size of simulated search space
#' @param num_children : number of children generated by each iteration  (e.g. 1 means sample size of 1 digit each,
#' 2 means 2 children, and so on)
#' @return ratio : a vector of boys ratio agains girls (in %)
#' @author Boutros El-Gamil
getAvgRatio<- function(iter, Ran_g, Ran_b, sample_size, num_children){
  # set ratio as empty vector
  ratio = c()
  
  # Case I: each couple has single child 
  if (num_children == 1){
    
    # repeat random number generation for iter times
    for (i in 1:iter){
      
      # generate random population of length sample_size, in range boys and girls  
      population = sample(min(Ran_g, Ran_b):max(Ran_g, Ran_b), sample_size, replace=T)
      
      # compute threshold of girls values (after it the random number considered as a boy)
      th = max(Ran_g)
      
      # abbend ratio of boys to it's vector
      ratio = c(ratio, 100 * length(population[population > th]) / length(population))
    }
  }
  
  # Case II: each couple has more than a single child 
  else if (num_children > 1){
    # repeat random number generation for iter times
    for (i in 1:iter){
      
      # set 0 vector of population of length sample_size 
      population = rep(0, sample_size)
      
      # set threshold to 0
      th = 0
      
      # loop over number of children - 1
      for (l in 0:num_children-2){
        
        # update threshold to accomodate the power of digits corresponded to number of children
        th = th + 10^l
        
        # generate (intermediate) random population of length sample_size 
        population_inter = sample(min(Ran_g):max(Ran_g), sample_size, replace=T)
        # append it to population, multiplied by 10 ^ l
        population = population + (10^l * population_inter)
      }
      
      # for last child, update threshold and multiply it by max. value of girls simulation
      th = th + 10^(num_children-1) 
      th = th * max(Ran_g)
      
      # update population for last time, by enable the last (intermediate) random population  
      # to range over all ranges of boy and girl simulation (as the problem states), if the last
      # child is a boy, the couple stop having children
      population_inter = sample(min(Ran_g):max(Ran_b), sample_size, replace=T)
      population = population + (10^(num_children-1) * population_inter)
      
      # abbend ratio of boys to it's vector
      ratio = c(ratio, 100 * length(population[population > th ]) / length(population))
      
    }
  }
  
  # print threshold value over each case
  print(paste0("Threshold:      ", th))
  # return average ratio  
  return(mean(ratio))  
  
}

#' simulation() compute ratio of boys and girls in the predefined problem
#' @author Boutros El-Gamil
simulation<- function(){
  # STEP 1 Possible Outcomes:
  # couples continue to have children
  # couples stop to have children
  
  # STEP 2 Link Outcomes To Probabilities:
  # prob. that couples continue to have children, last child is a girl!
  P_g = .5
  # prob. that couples stop to have children, last child is a boy!
  P_b = .5
  
  # STEP 3 Link Random Numbers To Outcomes 
  # consider 2 sets of digits 'Ran_g' & 'Ran_b', representing the prob. that a child is a girl or boy
  Ran_g = c(0, 1, 2, 3, 4)
  Ran_b = c(5, 6, 7, 8, 9)
  
  # STRP 4 Generate Random Numbers & Compute Ratio
  # for this step, we'll consider generating random numbers of 1, 2, and 3 digits, corresponded to 
  # couples with 1, 2, or 3 children, respectivily. 
  # User can consider sampling of more children by switching the last arg. of function
  # (getAvgRatio)
  
  # Case I: couples with single child
  ratio_b = getAvgRatio(1000, Ran_g, Ran_b, 500, 1)
  
  # print average ratio of boys over 1000 iterations to ratio of girls
  print(paste0("Case I: single child"))
  print(paste0("Ratio Boys To Girls:      ", round(ratio_b, 0), ":", 100 - round(ratio_b, 0)))
  
  # Case II: couples with two children
  ratio_b = getAvgRatio(1000, Ran_g, Ran_b, 500, 2)
  
  # print average ratio of boys over 1000 iterations to ratio of girls
  print(paste0("Case II: two children"))
  print(paste0("Ratio Boys To Girls:      ", round(ratio_b, 0), ":", 100 - round(ratio_b, 0)))
  
  # Case III: couples with three children
  ratio_b = getAvgRatio(1000, Ran_g, Ran_b, 500, 3)
  
  # print average ratio of boys over 1000 iterations to ratio of girls
  print(paste0("Case III: three children"))
  print(paste0("Ratio Boys To Girls:      ", round(ratio_b, 0), ":", 100 - round(ratio_b, 0)))
}

# 3. Analyzing a Data Set
dataAnalysis<- function(){
  
}

# 4. Submitting your results
resultsSubmission<- function(){
  
}

#'  Multiple plot function
#' 
#'  ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
#'  - cols:   Number of columns in layout
#'  - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#' 
#'  If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
#'  then plot 1 will go in the upper left, 2 will go in the upper right, and
#'  3 will go all the way across the bottom.
#' 
#'  SOURCE: Cookbook for R
#'  http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)
  
  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)
  
  numPlots = length(plots)
  
  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                     ncol = cols, nrow = ceiling(numPlots/cols))
  }
  
  if (numPlots==1) {
    print(plots[[1]])
    
  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
    
    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
      
      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

# Get lower triangle of the correlation matrix
get_lower_tri<-function(cormat){
  cormat[upper.tri(cormat)] <- NA
  return(cormat)
}

# Get upper triangle of the correlation matrix
get_upper_tri <- function(cormat){
  cormat[lower.tri(cormat)]<- NA
  return(cormat)
}

#' linearRegression(data, test_size, dep_var, ind_vars) build a linear regression model on training data, predicts 
#' accuracy of the model over test data, and reterns R^2 value of the predictive model 
#' @param data : original dataset
#' @param test_size : percentage of test data size (in decimal)
#' @param dep_var : name of the dependent variable
#' @param ind_vars : list of independent variables to build the model
#' @return R_squared : R^2 value of the predictive model
#' @author Boutros El-Gamil
linearRegression <- function(data, test_size, dep_var, ind_vars){
  set.seed(3000)
  if(!("ID" %in% colnames(data))){
    # add ID column to data
    data$ID <- seq.int(nrow(data))
  }
  
  # select random 10% of data as testing data, and the rest as training data
  d_test = data[sample(nrow(data), round(nrow(data) * test_size)), ]
  d_train = data[ !(data$ID %in% d_test$ID), ]
  
  # drop ID column
  data =  data[ , -which(names(data) %in% c("ID"))]
  d_test =  d_test[ , -which(names(d_test) %in% c("ID"))]
  d_train =  d_train[ , -which(names(d_train) %in% c("ID"))]
  
  # linear regression
  # build regression model
  f = paste(dep_var, "~", paste(ind_vars, collapse=" + "))
  model1 = lm(f, data = d_train)
  predictTest = predict(model1, newdata = d_test)
  
  SSE = sum((d_test$income - predictTest)^2)
  SST = sum((d_test$income - mean(data$income))^2)
  
  R_squared = 1 - SSE/SST
  
  return(R_squared)
}

#' cartModel(data, test_size, dep_var, ind_vars) build CART model on training data, predicts 
#' accuracy of the model over test data, and reterns accuracy of the predictive model 
#' @param data : original dataset
#' @param test_size : percentage of test data size (in decimal)
#' @param dep_var : name of the dependent variable
#' @param ind_vars : list of independent variables to build the model
#' @return accuracy : accuracy of the predictive model 
#' @author Boutros El-Gamil
cartModel <- function(data, test_size, dep_var, ind_vars){
  library(rpart)
  set.seed(3000)
  if(!("ID" %in% colnames(data))){
    # add ID column to data
    data$ID <- seq.int(nrow(data))
  }
  
  # select random 10% of data as testing data, and the rest as training data
  d_test = data[sample(nrow(data), round(nrow(data) * test_size)), ]
  d_train = data[ !(data$ID %in% d_test$ID), ]
  
  # drop ID column
  data =  data[ , -which(names(data) %in% c("ID"))]
  d_test =  d_test[ , -which(names(d_test) %in% c("ID"))]
  d_train =  d_train[ , -which(names(d_train) %in% c("ID"))]
  
  # build CART model
  f = paste(dep_var, "~", paste(ind_vars, collapse=" + "))
  model1 = rpart(f, data = d_train, method="class", minbucket=25)
  predictTest = predict(model1, newdata = d_test, type = "class")
  
  # f2= paste('d_test$', dep_var, sep = '')
  # print(eval(parse(f2)))
  
  conf_matrix = table(d_test[[dep_var]], predictTest)
  
  accuracy = (conf_matrix[1] + conf_matrix[4]) / sum(conf_matrix)
  return(accuracy)
}

#' univariateAnalysis(d_con_scaled, d_cat) runs uni-variate data analysis by visualizing  
#' a list of continues variables & categorical variables as histograms
#' @param d_con_scaled : dataframe of continues variables, scaled in [0,1]
#' @param d_cat : dataframe of categorical variables
#' @return ggplot2 plots saved to working directory
#' @author Boutros El-Gamil
univariateAnalysis<- function(d_con_scaled, d_cat){
  ## visualization
  library(ggplot2)
  library(reshape2)
  
  ## Univariate Analysis
  # continuous data histogram
  ggplot(data = melt(d_con_scaled), mapping = aes(x = value)) + 
    geom_histogram(bins = 15) + facet_wrap(~variable, scales = 'free_x')
  
  ggsave("hist2.png")
  
  # categorical data count
  p1 = ggplot(data = d_cat, mapping = aes(x = education )) + geom_bar() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  p2 = ggplot(data = d_cat, mapping = aes(x = MaritalStatus )) + geom_bar() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  p3 = ggplot(data = d_cat, mapping = aes(x = occupation )) + geom_bar() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  p4 = ggplot(data = d_cat, mapping = aes(x = relationship )) + geom_bar() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  p5 = ggplot(data = d_cat, mapping = aes(x = race )) + geom_bar() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  p6 = ggplot(data = d_cat, mapping = aes(x = sex )) + geom_bar() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  p7 = ggplot(data = d_cat, mapping = aes(x = NativeCountry )) + geom_bar() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  p8 = ggplot(data = d_cat, mapping = aes(x = income )) + geom_bar() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  multiplot(p1, p2, p3, p4, p5, p6, p7, p8, cols=2)
  ggsave("hist3.png")
}

#' bivariateAnalysis(d_con_scaled, d_cat) runs bi-variate data analysis by visualizing  
#' a list of continues variables as bi-correlation heatmap
#' @param d_con_scaled : dataframe of continues variables, scaled in [0,1]
#' @param d_cat : dataframe of categorical variables
#' @return ggplot2 plot saved to working directory
#' @author Boutros El-Gamil
bivariateAnalysis<- function(d_con_scaled, d_cat){
  ## visualization
  library(ggplot2)
  library(reshape2)
  
  ## Bi-ivariate Analysis
  # add 'income' feature to scaled continuous data
  d_con_scaled$income_chr = d_cat$income
  
  # set income variable to d_con_scaled ad numerical variable
  d_con_scaled$income = 0
  d_con_scaled = within(d_con_scaled, income[income_chr == ' >50K'] <- 1)
  d_con_scaled =  d_con_scaled[ , -which(names(d_con_scaled) %in% c("income_chr"))]
  
  
  cormat <- round(cor(d_con_scaled),2)
  upper_tri <- get_upper_tri(cormat)
  
  melted_cormat <- melt(upper_tri, na.rm = TRUE)
  
  ggplot(data = melted_cormat, aes(Var2, Var1, fill = value))+
    geom_tile(color = "white")+
    scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                         midpoint = 0, limit = c(-1,1), space = "Lab", 
                         name="Pearson\nCorrelation") +
    theme_minimal()+ 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                     size = 12, hjust = 1))+
    coord_fixed()
  
  ggsave("map1.png")
}
